Date,Name,Title,Abstract,Room,Hours,Meet
24/1/2025,Calogero Turco,Trust Approaches in Self-Sovereign Identity,"Digital Identity today is mainly centralized, with platforms like Google and Facebook controlling user's data. This lack of control has led to significant privacy concerns, such as the Cambridge Analytica scandal. Self-Sovereign Identity (SSI) is a paradigm shift that decentralizes Digital Identity by giving control back to the individuals it refers to. In SSI, individuals are called Holders and can decide what parts of their identity to expose. Each Holder has Verifiable Credentials (e.g., degree) in their digital wallet, issued by entities called Issuers (e.g., University). Holders present those Verifiable Credentials to any subject interested in information about them and who can act as a Verifier (e.g., recruiter). Unfortunately, no consolidated solutions exist to certify the Issuer's trustworthiness in issuing a specific credential or that the Holder can trust the Verifier in managing their sensitive data. How do we ensure that Issuers are trustworthy and Verifiers are competent to handle sensitive data responsibly? We will see some proposed methods for this and evaluate their suitability for different scenarios. Resolving these issues is essential to fully realizing the potential of SSI and creating a more secure, user-centric Digital Identity ecosystem.",Sala Riunioni Est,15:00-16:00,https://teams.microsoft.com/l/message/19:DkLh2QJfJIzQp_SpEuyUvxNI3ktQUEzrE2Aob9rjKVE1@thread.tacv2/1737121418482?tenantId=c7456b31-a220-47f5-be52-473828670aa1&groupId=e1ec02a8-5e74-4f1f-a340-920ec77b16bf&parentMessageId=1737121418482&teamName=40th%20CS%20Ph.D.%20cycle%20Pesaresi%20Seminar%20Series&channelName=General&createdTime=1737121418482,
07/2/2025,Michele Papucci,Toronto is the capital of Canada: Detecting and Preventing LLMs from Hallucinating,"Large Language Models (LLMs) have revolutionized Natural Language Processing (NLP) applications, reaching new state-of-the-art performances in all kinds of tasks and domains, especially in content generation scenarios. However, these models are prone to generating Hallucinations, which are factually incorrect, misleading, and non-sensical outputs that are presented in a convincingly accurate manner. This phenomenon poses significant risks, particularly in fields such as healthcare, legal services, etc. This seminar will briefly present the nature of hallucinations in LLMs, their underlying causes, and the challenges in detecting them. By understanding and preventing hallucination, LLM reliability can be improved, ensuring safer and more trustworthy AI applications.",Sala Riunioni Est,15:00-16:00,https://teams.microsoft.com/l/meetup-join/19%3aDkLh2QJfJIzQp_SpEuyUvxNI3ktQUEzrE2Aob9rjKVE1%40thread.tacv2/1738577547426?context=%7b%22Tid%22%3a%22c7456b31-a220-47f5-be52-473828670aa1%22%2c%22Oid%22%3a%22919a988f-192a-44fb-85ea-da1c780ea337%22%7d
14/2/2025,Jack Bell,Bridging the ARC: From Intrigue to Innovation,"The ARC (Abstract Reasoning Corpus) Prize, emphasising skill acquisition over task-specific performance, redefines how intelligence, both human and artificial, should be measured. It builds on insights challenging traditional benchmarks and posits that true intelligence lies in an agentâ€™s ability to rapidly learn and generalise from minimal exposure, as opposed to performing well only on predefined tasks with extensive training data. The ARC Benchmark presents abstract, open-ended problems designed to test human-like reasoning and adaptability, while the ARC Prize incentivises interdisciplinary approaches that blend rigorous theoretical analysis with practical data-driven approaches. Together, they tackle challenges such as scalability, inherent randomness and non-determinism, catalysing a paradigm shift toward AI systems that embody generalisable intelligence.",Sala Demo,14:00-15:00,https://teams.microsoft.com/l/message/19:DkLh2QJfJIzQp_SpEuyUvxNI3ktQUEzrE2Aob9rjKVE1@thread.tacv2/1738577547426?tenantId=c7456b31-a220-47f5-be52-473828670aa1&groupId=e1ec02a8-5e74-4f1f-a340-920ec77b16bf&parentMessageId=1738577547426&teamName=Pesaresi%20Seminar%20Series%202025&channelName=General&createdTime=1738577547426
21/2/2025,Elisa Salatti,Designing eHealth systems for people with disabilities: from personalization to universality,"Access to quality healthcare services is a recognized human right. Despite the use of technology, this right is not guaranteed for everyone, especially people with disabilities. Designing eHealth systems for people with disabilities requires an interdisciplinary approach and a balance between personalization and universality. We have technologies, methods and tools to develop systems that solve specific access problems in healthcare. However, to achieve universal products and reduce costs, the results of these efforts must be generalized. This seminar addresses the challenges and opportunities in developing inclusive eHealth systems and emphasizes the importance of a participatory approach to improve the accessibility and quality of healthcare for all.", Sala Demo, 14:00-15:00,https://teams.microsoft.com/l/message/19:DkLh2QJfJIzQp_SpEuyUvxNI3ktQUEzrE2Aob9rjKVE1@thread.tacv2/1739624120665?tenantId=c7456b31-a220-47f5-be52-473828670aa1&groupId=e1ec02a8-5e74-4f1f-a340-920ec77b16bf&parentMessageId=1739624120665&teamName=Pesaresi%20Seminar%20Series%202025&channelName=General&createdTime=1739624120665