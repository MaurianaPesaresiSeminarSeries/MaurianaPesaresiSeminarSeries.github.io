.row.mt-4.mb-4
  h2 #[span.emoji ðŸ”®] Next Talks

.row.project
  .col-md-2.col-3
    h3.mb-0 26th
    h5.month.mb-0 January
    p 15:00-16:00
  .col-md-7.col-9
    p.author #[span.me Ben William Gerriety Cullen]
    h4.title.mb-1
      |  Topologically Informed Graph Neural Networks
    .btn-group.btn-group-sm(role="group",aria-label="Commands").mt-1
      
      button.btn.btn-primary(type="button",data-bs-toggle="collapse",data-bs-target="#talk-c3a901b518fc5be1902cfb7cbcc2e487",aria-expanded="false",aria-controls="talk-c3a901b518fc5be1902cfb7cbcc2e487")
        | #[i.bi.bi-file-earmark-text-fill] Abstract
  .col-md-7
    p.abstract#talk-c3a901b518fc5be1902cfb7cbcc2e487.collapse.mt-2
        | Unlike traditional machine learning (ML) paradigms, graph neural networks (GNNs) are a class of ML models that can process graph structured data natively. Such models have proven successful in many diverse applications such as computational chemistry, biology, drug design, and social network analysis; however theoretical frameworks for understanding their expressivity - that is their power  - are scarce. Analysis of the expressivity of graph based models is either done empirically using standard data sets (as determined by the literature) or with recourse to their comparison with the Weisfeiler Lehmann (WL) heuristics for graph isomorphism testing. The latter has proven successful in both understanding the sufficient conditions for optimising the expressivity of a standard GNN as well as the development of more expressive models such as k-GNNs. However, several seminal publications have demonstrated that GNNs that are determined expressive in the WL framework perform poorly on substructure identification tasks. Such tasks are crucial for the aforementioned applications and, consequently, the scope of expressivity must encompass them. In this presentation we explore the fundamentals of GNNs and their importance as a model class in machine learning. We discuss the Weisfeiler-Lehman framework for expressivity, providing examples of how these heuristics compare to the computational capabilities of standard GNNs and hence allow us to better understand their behaviour.  Furthermore, we consider why GNNs struggle on tasks that involve substructure identification and hence motivate the application of concepts in algebraic topology for the development of new topologically informed graph neural networks.