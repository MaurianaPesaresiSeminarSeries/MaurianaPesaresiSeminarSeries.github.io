.row.mt-4.mb-2
  h2 #[span.emoji ðŸš€] Upcoming

.row.next
  .col-md-7.col-8
    p.author #[span.me Jack Bell]
    h2.title.mb-0.mt-1
      | Bridging the ARC: From Intrigue to Innovation
  .col-md-2.col-4
    h1.day 14th
    h4.month.mb-0 February
    p 14:00-15:00
  .col-md-7.col-12.mt-sm-3.mt-lg-1
      p
        | The ARC (Abstract Reasoning Corpus) Prize, emphasising skill acquisition over task-specific performance, redefines how intelligence, both human and artificial, should be measured. It builds on insights challenging traditional benchmarks and posits that true intelligence lies in an agentâ€™s ability to rapidly learn and generalise from minimal exposure, as opposed to performing well only on predefined tasks with extensive training data. The ARC Benchmark presents abstract, open-ended problems designed to test human-like reasoning and adaptability, while the ARC Prize incentivises interdisciplinary approaches that blend rigorous theoretical analysis with practical data-driven approaches. Together, they tackle challenges such as scalability, inherent randomness and non-determinism, catalysing a paradigm shift toward AI systems that embody generalisable intelligence.
  .col-md-4.d-grid.gap-2.d-md-block
    
    a(href="https://teams.microsoft.com/l/message/19:DkLh2QJfJIzQp_SpEuyUvxNI3ktQUEzrE2Aob9rjKVE1@thread.tacv2/1738577547426?tenantId=c7456b31-a220-47f5-be52-473828670aa1&groupId=e1ec02a8-5e74-4f1f-a340-920ec77b16bf&parentMessageId=1738577547426&teamName=Pesaresi%20Seminar%20Series%202025&channelName=General&createdTime=1738577547426").btn.btn-primary.mb-md-3.w-100
      | #[i.bi.bi-camera-reels-fill] Live Streaming
    a(href="https://goo.gl/maps/FL4qcbB3MnMXrYS28",target="_blank").btn.btn-primary.w-100
      | #[i.bi.bi-geo-alt-fill] Sala Demo
      