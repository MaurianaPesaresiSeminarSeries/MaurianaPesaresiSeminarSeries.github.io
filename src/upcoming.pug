.row.mt-4.mb-2
  h2 #[span.emoji ðŸš€] Upcoming

.row.next
  .col-md-7.col-8
    p.author #[span.me Cosimo Rulli]
    h2.title.mb-0.mt-1
      | Deep Neural Network Compression 
  .col-md-2.col-4
    h1.day 4th
    h4.month.mb-0 March
    p 15:00-16:00
  .col-md-7.col-12.mt-sm-3.mt-lg-1
      p
        | Deep Neural Networks (DNNs) deliver state-of-the-art performance in a plethora of different tasks, such Computer Vision, Natural Language Processing and Speech Recognition. Their effectiveness comes at the price of an elevated computational burden, in terms of memory occupancy, inference time, and energy consumption, which hinders their usage in resource-constrained devices. Model Compression techniques tackle this problem by leveraging the largely proved over-parametrization of modern DNNs and aim at the reducing the computational requirements of DNNs without affecting their accuracy. In this seminar, we illustrate the taxonomy of DNNs compression methods, particularly focusing on quantization, pruning and knowledge distillation. We introduce their technical aspects, and discuss the different trade-offs between computational burden and accuracy that each technique allows to achieve.
  .col-md-4.d-grid.gap-2.d-md-block
    a(href="https://calendar.google.com/event?action=TEMPLATE&tmeid=NGcxZGMxODNjbDdqaWY0djM3OTZzcmg1ZmUgY191MGNvOWZxb28xNTk3bWZydGFwdG1jMTlyMEBn&tmsrc=c_u0co9fqoo1597mfrtaptmc19r0%40group.calendar.google.com",target="_blank").btn.btn-primary.mb-md-3.w-100
      | #[i.bi.bi-calendar-event-fill] Add to Calendar
    a(href="https://meet.google.com/egw-bjya-aur").btn.btn-primary.mb-md-3.w-100
      | #[i.bi.bi-camera-reels-fill] Live Streaming
    a(href="https://goo.gl/maps/FL4qcbB3MnMXrYS28",target="_blank").btn.btn-primary.w-100
      | #[i.bi.bi-geo-alt-fill] Sala Seminari Est
      